% Uncomment this to make slides with overlays:
%\documentclass[slides]{beamer}

% Uncomment these (but comment the above \documentclass line) to make handouts:
\documentclass[handout]{beamer}

% Uncomment these to have more than one slide per page
\usepackage{pgfpages}
\pgfpagesuselayout{2 on 1}[border shrink=5mm]
\pgfpageslogicalpageoptions{1}{border code=\pgfusepath{stroke}}
\pgfpageslogicalpageoptions{2}{border code=\pgfusepath{stroke}}

\usepackage[]{graphicx, color, hyperref}

\mode<presentation>
{
	%\usetheme[secheader]{Boadilla}
	%\usecolortheme[rgb={.835, .102,.169}]{structure}  
	\usetheme[width= 0cm]{Goettingen}
	%\setbeamercovered{transparent}
}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}[frame number]

\definecolor{blue2}{rgb}{0.278,0.278,0.729} 
\newcommand{\blue}[1]{\textcolor{blue2}{#1}}
\newcommand{\white}[1]{\textcolor{white}{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\xbar}{\overline{x}}
\newcommand{\ybar}{\overline{y}}
\newcommand{\phat}{\widehat{p}}
\newcommand{\prob}{\mbox{Pr}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\cp}{\oplus}
\newcommand{\cm}{\circleddash}

\title{Lecture 14: Hypothesis Testing Part I}
\author{Chapter 4.3}
\date{}


\begin{document}
%------------------------------------------------------------------------------
\begin{frame}
\titlepage
\end{frame}
%------------------------------------------------------------------------------


%------------------------------------------------------------------------------
\begin{frame}[fragile]
\frametitle{Goals for Today}

\begin{itemize}
\item Introduce Hypothesis Testing Framework
\item Testing Hypotheses Using Confidence Intervals
\item Types of Errors
\item Testing Hypotheses Using p-Values
\end{itemize}

\end{frame}
%------------------------------------------------------------------------------


%-------------------------------------------------------------------------------
\begin{frame}
\frametitle{Statistical Hypothesis Testing}

%
% Comment this
%
(For now) A \blue{hypothesis} is a claim about a population parameter.

\vskip 0.25cm

\pause A \blue{hypothesis test} is a method for using sample data to decide between two competing hypotheses about the population parameter:
\begin{itemize}
\pause \item A \blue{null hypothesis $H_0$}.\\
i.e. the \blue{status quo} that is initially assumed to be true, but will be tested. 
\pause \item An \blue{alternative hypothesis $H_A$}.\\
i.e. the \blue{challenger}.
\end{itemize}

\end{frame}
%-------------------------------------------------------------------------------


%-------------------------------------------------------------------------------
\begin{frame}
\frametitle{Example}
We flip a coin many times and start to suspect that it is biased:
\pause\begin{itemize}
\item $H_0$: the coin is fair.  i.e. the probability of heads is $p=0.5$
\item $H_A$: the coin is not fair.  i.e. $p \neq 0.5$
\end{itemize}
\end{frame}
%-------------------------------------------------------------------------------


%-------------------------------------------------------------------------------
\begin{frame}
\frametitle{Crucial Concept: Conclusions of Hypothesis Tests}

%
% Comment this
%
There are two potential outcomes of a hypothesis test.  Either we
\pause \begin{itemize}
\item reject $H_0$ in favor of $H_A$
\item fail to reject $H_0$
\end{itemize}

\vspace{0.5cm}

\pause Note the difference between \blue{accepting $H_0$} \& \blue{failing to reject $H_0$}
\begin{itemize}
\pause \item ``accepting $H_0$'' is saying we are sure $H_0$ is true
\pause \item ``failing to reject $H_0$'' is saying something not as strong:  \blue{we do not have enough evidence to reject $H_0$}.
\end{itemize}

\end{frame}
%-------------------------------------------------------------------------------


%-------------------------------------------------------------------------------
\begin{frame}
\frametitle{Analogy:  US Criminal Justice System}

In the criminal justice system, the jury's verdict does NOT make any statement about the defendant being \blue{innocent}, rather that there was not enough evidence to prove beyond a reasonable doubt that they were guilty.

\end{frame}
%-------------------------------------------------------------------------------


%-------------------------------------------------------------------------------
\begin{frame}
\frametitle{Analogy:  US Criminal Justice System}

Let's compare criminal trials to hypothesis tests:

\vspace{0.5cm}

\pause \blue{Truth}:
\begin{itemize}
\item Truth about the defendant: innocent vs guilty
\item Truth about the hypothesis: $H_0$ or $H_A$
\end{itemize}

\vspace{0.25cm}

\pause \blue{Decision}:
\begin{itemize}
\item Verdict:  not guilty vs guilty
\item Test outcome: ``Do not reject $H_0$'' vs ``Reject $H_0$''
\end{itemize}

\end{frame}
%-------------------------------------------------------------------------------


%-------------------------------------------------------------------------------
\begin{frame}
\frametitle{Testing Hypotheses Using Confidence Intervals}
Example on page 173: The average 10 mile run time for the Cherry Blossom Run in 2006 $\mu_{2006}$ was 93.29 min.  Researchers suspect $\mu_{2012}$ was different:
\pause\begin{itemize}
\item $H_0$: average time was the same. i.e. $\mu_{2012} = 93.29$
\item $H_A$: average time was different. i.e. $\mu_{2012} \neq 93.29$
\end{itemize}

%\pause \vspace{0.5cm}
%
%93.29 is the \blue{null value} (typically denoted $\mu_{0}$) since it represents the value of the parameter if the null hypothesis is true.
%
%\pause \vspace{0.5cm}
%
%They take a sample of size $n=100$ times from 2012 and find that $\xbar_{2012}=95.61$ and $s=15.78$
%
%\pause \vspace{0.5cm}
%
%$\xbar_{2012} = 95.61 > 93.29 = \mu_0$.  Are they different?

\end{frame}
%-------------------------------------------------------------------------------


%-------------------------------------------------------------------------------
\begin{frame}
\frametitle{Testing Hypotheses Using Confidence Intervals}

%Recall that a 95\% confidence interval for the population mean $\mu$ based on a sample of points $x_1, \ldots, x_n$ is 
%
%\pause \begin{eqnarray*}
%\left[\overline{x} - 1.96 \times\frac{s}{\sqrt n}\right.,
%\left.\overline{x} + 1.96 \times\frac{s}{\sqrt n}\right] =\left[92.45\right., \left.98.77\right]
%\end{eqnarray*}
%
%Since the \blue{null value} 93.29 falls in the range of plausible values, we fail to reject $H_0$.  
%
%\pause \vspace{0.5cm}
%
%We are NOT saying that the 2006 and 2012 times are the same.  Rather that \blue{there is insufficient evidence to suggest otherwise}.

\end{frame}
%-------------------------------------------------------------------------------


%-------------------------------------------------------------------------------
\begin{frame}
\frametitle{Decision Errors}

%
% Comment this
%
Hypothesis tests will get things right sometimes and wrong sometimes:
\pause \begin{center}
  \begin{tabular}{cc|cc}
     \multicolumn{2}{c}{}  & \multicolumn{2}{c}{\textbf{Test conclusion}} \\ 
     &  & do not reject $H_0$ & reject $H_0$ in favor of $H_A$ \\ 
\hline
    \textbf{Truth} & $H_0$ true & OK & \blue{Type I Error} \\ 
     & $H_A$ true & \blue{Type II Error} & OK \\ 
    \hline
  \end{tabular}
\end{center}

\vspace{0.25cm}

\pause Two kinds of errors:
\begin{itemize}
\item \blue{Type I Error}: a false positive
\item \blue{Type II Error}: a false negative
\end{itemize}

\end{frame}
%-------------------------------------------------------------------------------


%-------------------------------------------------------------------------------
\begin{frame}
\frametitle{Decision Errors}
\begin{itemize}
\item Trade-off between these two error rates
\begin{itemize}
\item procedures with lower type I error rates typically have higher type II error rates
\item vice-versa
\end{itemize}
\pause \item In other words, there is almost never a procedure that makes no type I errors and no type II errors.  Some sort of balance between the two is required
\end{itemize}
\end{frame}
%-------------------------------------------------------------------------------


%------------------------------------------------------------------------------
\begin{frame}[fragile]
\frametitle{Next Time}

\begin{itemize}
\item More Hypothesis Testing
\end{itemize}

\end{frame}
%------------------------------------------------------------------------------




\end{document}














%-------------------------------------------------------------------------------
\begin{frame}
\frametitle{One vs Two Sided Hypothesis Tests}
This is a \blue{one-sided} hypothesis test.  Our test of a fair vs non fair coin was \blue{two-sided} since the alternative hypothesis was $H_A: p \neq 0.5$ i.e. $p>0.5$ or $p<0.5$
\end{frame}
%-------------------------------------------------------------------------------



%-------------------------------------------------------------------------------
\begin{frame}
\frametitle{Specifying a Test Procedure}
What is typically done is:
\begin{itemize}
\item Pick a desired $\alpha$ significance level and ``clamp'' the test to this $\alpha$.  Typical values include 0.10, 0.05, 0.01 and 0.001
\item Then pick the test that minimizes $\beta$.  
\end{itemize}
\vskip 0.25cm
So if you're in a situation where:
\begin{itemize}
\item Type I errors are much more serious than a type II error, set $\alpha$ to be lower and hence $\beta$ will be higher
\item Type II errors are much more serious, set $\beta$ to be lower and hence $\alpha$ will be higher
\end{itemize}
\end{frame}
%-------------------------------------------------------------------------------







